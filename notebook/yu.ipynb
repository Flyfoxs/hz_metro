{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['week_day', 'stationID', 'time_ex', 'bin_id', 'p', 'd', 'q', 'out_1', 'in_1', 'out_1_p', 'in_1_p', 'out_2', 'in_2', 'out_2_p', 'in_2_p', 'out_3', 'in_3', 'out_3_p', 'in_3_p']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-23 14:42:18,413 140737245463488 util_log.py[93] INFO Start the program at:LALI2-M-G0MD, 127.0.0.1, with:Load module\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "LALI2-M-G0MD\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from bokeh.palettes import Category10\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "#Adjust the working folder\n",
    "file_folder = globals()['_dh'][0]\n",
    "wk_dir = os.path.dirname(file_folder)\n",
    "os.chdir(wk_dir)\n",
    "from core.feature import *\n",
    "from core.estimate import *\n",
    "from core.db import *\n",
    "# from core.predict import *\n",
    "# from core.merge import *\n",
    "# from core.merge import *\n",
    "\n",
    "from file_cache.utils.util_pandas import *\n",
    "from file_cache.cache import file_cache\n",
    "from file_cache.utils.util_log import *\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "import argparse\n",
    "sys.argv = ['program',  '-W' , '--gp_name', 'lr_bin_9', '--shift', 0]\n",
    "\n",
    "\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "!hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from scipy.stats import norm, rankdata\n",
    "import warnings\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import metrics\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "sns.set(font_scale=1)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'input'\n",
    "test = pd.read_csv(path + '/Metro_testA/testA_submit_2019-01-29.csv')\n",
    "test_28 = pd.read_csv(path + '/Metro_testA/testA_record_2019-01-28.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_base_features(df_):\n",
    "    \n",
    "    df = df_.copy()\n",
    "    \n",
    "    # base time\n",
    "    df['day']     = df['time'].apply(lambda x: int(x[8:10]))\n",
    "    df['week']    = pd.to_datetime(df['time']).dt.dayofweek + 1\n",
    "    df['weekend'] = (pd.to_datetime(df.time).dt.weekday >=5).astype(int)\n",
    "    df['hour']    = df['time'].apply(lambda x: int(x[11:13]))\n",
    "    df['minute']  = df['time'].apply(lambda x: int(x[14:15]+'0'))\n",
    "    \n",
    "    # count,sum\n",
    "    result = df.groupby(['stationID', 'week', 'weekend', 'day', 'hour', 'minute']).status.agg(['count', 'sum']).reset_index()\n",
    "    \n",
    "    # nunique\n",
    "    tmp     = df.groupby(['stationID'])['deviceID'].nunique().reset_index(name='nuni_deviceID_of_stationID')\n",
    "    result  = result.merge(tmp, on=['stationID'], how='left')\n",
    "    tmp     = df.groupby(['stationID','hour'])['deviceID'].nunique().reset_index(name='nuni_deviceID_of_stationID_hour')\n",
    "    result  = result.merge(tmp, on=['stationID','hour'], how='left')\n",
    "    tmp     = df.groupby(['stationID','hour','minute'])['deviceID'].nunique().\\\n",
    "                                           reset_index(name='nuni_deviceID_of_stationID_hour_minute')\n",
    "    result  = result.merge(tmp, on=['stationID','hour','minute'], how='left')\n",
    "    \n",
    "    # in,out\n",
    "    result['inNums']  = result['sum']\n",
    "    result['outNums'] = result['count'] - result['sum']\n",
    "    \n",
    "    #\n",
    "    result['day_since_first'] = result['day'] - 1 \n",
    "    result.fillna(0, inplace=True)\n",
    "    del result['sum'],result['count']\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-23 14:42:22,690 140737245463488 util_log.py[48] INFO get_data begin with(0 paras) :[], []\n",
      "2019-03-23 14:42:22,970 140737245463488 util_log.py[63] INFO cost 00.3 sec:get_data([], []), return:DF:(234847, 12), end \n"
     ]
    }
   ],
   "source": [
    "@file_cache()\n",
    "def get_data():\n",
    "    data = get_base_features(test_28)\n",
    "    data_list = os.listdir(path+'/Metro_train/')\n",
    "    for i in range(0, len(data_list)):\n",
    "        if data_list[i].split('.')[-1] == 'csv':\n",
    "            print(data_list[i], i)\n",
    "            df = pd.read_csv(path+'/Metro_train/' + data_list[i])\n",
    "            df = get_base_features(df)\n",
    "            data = pd.concat([data, df], axis=0, ignore_index=True)\n",
    "        else:\n",
    "            continue\n",
    "    return data\n",
    "\n",
    "data = get_data()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 剔除周末,并修改为连续时间\n",
    "data = data[(data.day!=5)&(data.day!=6)]\n",
    "data = data[(data.day!=12)&(data.day!=13)]\n",
    "data = data[(data.day!=19)&(data.day!=20)]\n",
    "data = data[(data.day!=26)&(data.day!=27)]\n",
    "\n",
    "def fix_day(d):\n",
    "    if d in [1,2,3,4]:\n",
    "        return d\n",
    "    elif d in [7,8,9,10,11]:\n",
    "        return d - 2\n",
    "    elif d in [14,15,16,17,18]:\n",
    "        return d - 4\n",
    "    elif d in [21,22,23,24,25]:\n",
    "        return d - 6\n",
    "    elif d in [28]:\n",
    "        return d - 8\n",
    "data['day'] = data['day'].apply(fix_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['week']    = pd.to_datetime(test['startTime']).dt.dayofweek + 1\n",
    "test['weekend'] = (pd.to_datetime(test.startTime).dt.weekday >=5).astype(int)\n",
    "test['day']     = test['startTime'].apply(lambda x: int(x[8:10]))\n",
    "test['hour']    = test['startTime'].apply(lambda x: int(x[11:13]))\n",
    "test['minute']  = test['startTime'].apply(lambda x: int(x[14:15]+'0'))\n",
    "test['day_since_first'] = test['day'] - 1\n",
    "test = test.drop(['startTime','endTime'], axis=1)\n",
    "data = pd.concat([data,test], axis=0, ignore_index=True)\n",
    "\n",
    "stat_columns = ['inNums','outNums']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_refer_day(d):\n",
    "    if d == 20:\n",
    "        return 29\n",
    "    else:\n",
    "        return d + 1\n",
    "\n",
    "tmp = data.copy()\n",
    "tmp_df = tmp[tmp.day==1]\n",
    "tmp_df['day'] = tmp_df['day'] - 1\n",
    "tmp = pd.concat([tmp, tmp_df], axis=0, ignore_index=True)\n",
    "tmp['day'] = tmp['day'].apply(get_refer_day)\n",
    "\n",
    "for f in stat_columns:\n",
    "    tmp.rename(columns={f: f+'_last'}, inplace=True) \n",
    "    \n",
    "tmp = tmp[['stationID','day','hour','minute','inNums_last','outNums_last']]\n",
    "\n",
    "data = data.merge(tmp, on=['stationID','day','hour','minute'], how='left')\n",
    "data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = data.groupby(['stationID','week','hour','minute'], as_index=False)['inNums'].agg({\n",
    "                                                                        'inNums_whm_max'    : 'max',\n",
    "                                                                        'inNums_whm_min'    : 'min',\n",
    "                                                                        'inNums_whm_mean'   : 'mean'\n",
    "                                                                        })\n",
    "data = data.merge(tmp, on=['stationID','week','hour','minute'], how='left')\n",
    "\n",
    "tmp = data.groupby(['stationID','week','hour','minute'], as_index=False)['outNums'].agg({\n",
    "                                                                        'outNums_whm_max'    : 'max',\n",
    "                                                                        'outNums_whm_min'    : 'min',\n",
    "                                                                        'outNums_whm_mean'   : 'mean'\n",
    "                                                                        })\n",
    "data = data.merge(tmp, on=['stationID','week','hour','minute'], how='left')\n",
    "\n",
    "tmp = data.groupby(['stationID','week','hour'], as_index=False)['inNums'].agg({\n",
    "                                                                        'inNums_wh_max'    : 'max',\n",
    "                                                                        'inNums_wh_min'    : 'min',\n",
    "                                                                        'inNums_wh_mean'   : 'mean'\n",
    "                                                                        })\n",
    "data = data.merge(tmp, on=['stationID','week','hour'], how='left')\n",
    "\n",
    "tmp = data.groupby(['stationID','week','hour'], as_index=False)['outNums'].agg({\n",
    "                                                                        #'outNums_wh_max'    : 'max',\n",
    "                                                                        #'outNums_wh_min'    : 'min',\n",
    "                                                                        'outNums_wh_mean'   : 'mean'\n",
    "                                                                        })\n",
    "data = data.merge(tmp, on=['stationID','week','hour'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recover_day(d):\n",
    "    if d in [1,2,3,4]:\n",
    "        return d\n",
    "    elif d in [5,6,7,8,9]:\n",
    "        return d + 2\n",
    "    elif d in [10,11,12,13,14]:\n",
    "        return d + 4\n",
    "    elif d in [15,16,17,18,19]:\n",
    "        return d + 6\n",
    "    elif d == 20:\n",
    "        return d + 8\n",
    "    else:\n",
    "        return d\n",
    "\n",
    "all_columns = [f for f in data.columns if f not in ['weekend','inNums','outNums']]\n",
    "data=data[data.day>1]\n",
    "\n",
    "### all data\n",
    "all_data = data[data.day!=29]\n",
    "all_data['day'] = all_data['day'].apply(recover_day)\n",
    "X_data = all_data[all_columns].values\n",
    "\n",
    "train = data[data.day <20]\n",
    "train['day'] = train['day'].apply(recover_day)\n",
    "X_train = train[all_columns].values\n",
    "\n",
    "valid = data[data.day==20]\n",
    "valid['day'] = valid['day'].apply(recover_day)\n",
    "X_valid = valid[all_columns].values\n",
    "\n",
    "test  = data[data.day==29]\n",
    "X_test = test[all_columns].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171981, 24) (162857, 24) (9124, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>day_since_first</th>\n",
       "      <th>hour</th>\n",
       "      <th>inNums</th>\n",
       "      <th>minute</th>\n",
       "      <th>nuni_deviceID_of_stationID</th>\n",
       "      <th>nuni_deviceID_of_stationID_hour</th>\n",
       "      <th>nuni_deviceID_of_stationID_hour_minute</th>\n",
       "      <th>outNums</th>\n",
       "      <th>stationID</th>\n",
       "      <th>week</th>\n",
       "      <th>weekend</th>\n",
       "      <th>inNums_last</th>\n",
       "      <th>outNums_last</th>\n",
       "      <th>inNums_whm_max</th>\n",
       "      <th>inNums_whm_min</th>\n",
       "      <th>inNums_whm_mean</th>\n",
       "      <th>outNums_whm_max</th>\n",
       "      <th>outNums_whm_min</th>\n",
       "      <th>outNums_whm_mean</th>\n",
       "      <th>inNums_wh_max</th>\n",
       "      <th>inNums_wh_min</th>\n",
       "      <th>inNums_wh_mean</th>\n",
       "      <th>outNums_wh_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [day, day_since_first, hour, inNums, minute, nuni_deviceID_of_stationID, nuni_deviceID_of_stationID_hour, nuni_deviceID_of_stationID_hour_minute, outNums, stationID, week, weekend, inNums_last, outNums_last, inNums_whm_max, inNums_whm_min, inNums_whm_mean, outNums_whm_max, outNums_whm_min, outNums_whm_mean, inNums_wh_max, inNums_wh_min, inNums_wh_mean, outNums_wh_mean]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(all_data.shape, train.shape, valid.shape)\n",
    "all_data.loc[all_data.day==1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day                                          2.000000\n",
       "day_since_first                              1.000000\n",
       "hour                                        16.000000\n",
       "inNums                                     822.000000\n",
       "minute                                      50.000000\n",
       "nuni_deviceID_of_stationID                  31.000000\n",
       "nuni_deviceID_of_stationID_hour             30.000000\n",
       "nuni_deviceID_of_stationID_hour_minute      30.000000\n",
       "outNums                                    372.000000\n",
       "stationID                                    9.000000\n",
       "week                                         3.000000\n",
       "weekend                                      0.000000\n",
       "inNums_last                               1727.000000\n",
       "outNums_last                               789.000000\n",
       "inNums_whm_max                             864.000000\n",
       "inNums_whm_min                             630.000000\n",
       "inNums_whm_mean                            764.000000\n",
       "outNums_whm_max                            513.000000\n",
       "outNums_whm_min                            298.000000\n",
       "outNums_whm_mean                           395.250000\n",
       "inNums_wh_max                              967.000000\n",
       "inNums_wh_min                              603.000000\n",
       "inNums_wh_mean                             754.791667\n",
       "outNums_wh_mean                            397.708333\n",
       "Name: 19167, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.iloc[10226] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     9046\n",
       "3     9028\n",
       "4     8968\n",
       "7     8959\n",
       "8     8989\n",
       "9     9086\n",
       "10    9038\n",
       "11    9006\n",
       "14    8946\n",
       "15    9023\n",
       "16    8974\n",
       "17    9072\n",
       "18    8984\n",
       "21    9069\n",
       "22    9153\n",
       "23    9188\n",
       "24    9147\n",
       "25    9181\n",
       "28    9124\n",
       "Name: day, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.day.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162857, 21) (162857,) (9124, 21) (9124,)\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttrain's l1: 10.4963\tvalid's l1: 13.529\n",
      "[2000]\ttrain's l1: 9.95913\tvalid's l1: 13.3109\n",
      "[3000]\ttrain's l1: 9.57023\tvalid's l1: 13.2275\n",
      "[4000]\ttrain's l1: 9.25785\tvalid's l1: 13.1566\n",
      "[5000]\ttrain's l1: 8.98526\tvalid's l1: 13.1201\n",
      "Early stopping, best iteration is:\n",
      "[5313]\ttrain's l1: 8.90981\tvalid's l1: 13.1123\n",
      "[1000]\ttrain's l1: 10.5912\n",
      "[2000]\ttrain's l1: 10.0491\n",
      "[3000]\ttrain's l1: 9.66146\n",
      "[4000]\ttrain's l1: 9.34661\n",
      "[5000]\ttrain's l1: 9.08439\n",
      "Training until validation scores don't improve for 200 rounds.\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'num_leaves': 63,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.9,\n",
    "    'bagging_seed':0,\n",
    "    'bagging_freq': 1,\n",
    "    'verbose': 1,\n",
    "    'reg_alpha':1,\n",
    "    'reg_lambda':2\n",
    "}\n",
    "\n",
    "######################################################inNums\n",
    "y_train = train['inNums']\n",
    "y_valid = valid['inNums']\n",
    "y_data  = all_data['inNums']\n",
    "print(X_train.shape, y_train.shape, X_valid.shape, y_valid.shape)\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_evals = lgb.Dataset(X_valid, y_valid , reference=lgb_train)\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=10000,\n",
    "                valid_sets=[lgb_train,lgb_evals],\n",
    "                valid_names=['train','valid'],\n",
    "                early_stopping_rounds=200,\n",
    "                verbose_eval=1000,\n",
    "                )\n",
    "\n",
    "### all_data\n",
    "lgb_train = lgb.Dataset(X_data, y_data)\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=gbm.best_iteration,\n",
    "                valid_sets=[lgb_train],\n",
    "                valid_names=['train'],\n",
    "                verbose_eval=1000,\n",
    "                )\n",
    "test['inNums'] = gbm.predict(X_test)\n",
    "\n",
    "######################################################outNums\n",
    "y_train = train['outNums']\n",
    "y_valid = valid['outNums']\n",
    "y_data  = all_data['outNums']\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_evals = lgb.Dataset(X_valid, y_valid , reference=lgb_train)\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=10000,\n",
    "                valid_sets=[lgb_train,lgb_evals],\n",
    "                valid_names=['train','valid'],\n",
    "                early_stopping_rounds=200,\n",
    "                verbose_eval=1000,\n",
    "                )\n",
    "\n",
    "### all_data\n",
    "lgb_train = lgb.Dataset(X_data, y_data)\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=gbm.best_iteration,\n",
    "                valid_sets=[lgb_train],\n",
    "                valid_names=['train'],\n",
    "                verbose_eval=1000,\n",
    "                )\n",
    "test['outNums'] = gbm.predict(X_test)\n",
    "\n",
    "sub = pd.read_csv(path + '/Metro_testA/testA_submit_2019-01-29.csv')\n",
    "sub['inNums']   = test['inNums'].values\n",
    "sub['outNums']  = test['outNums'].values\n",
    "# 结果修正\n",
    "sub.loc[sub.inNums<0 , 'inNums']  = 0\n",
    "sub.loc[sub.outNums<0, 'outNums'] = 0\n",
    "file = f'output/sub_model_{int(time.time() % 10000000)}.csv'\n",
    "sub[['stationID', 'startTime', 'endTime', 'inNums', 'outNums']].to_csv(file, index=False)\n",
    "#13.1495, 15.0403"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
